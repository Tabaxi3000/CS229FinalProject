% Reward Structure Section for CS229 Project

\subsubsection{Reward Structure}

Our reward system combines end-game outcomes with intermediate feedback to guide the learning process. Players receive rewards not just for winning, but also for making strategic moves that improve their position. When reward shaping is enabled, the total reward $R(s,a,s')$ includes both terminal and intermediate rewards:

\[
R(s,a,s') = \begin{cases}
R_{terminal}(s,a,s') & \text{without shaping} \\
R_{terminal}(s,a,s') + R_{shaped}(s,a,s') & \text{with shaping}
\end{cases}
\]

Terminal rewards reflect match outcomes, with different scaling factors ($\alpha$) depending on how the game ends:
\[
R_{terminal}(s,a,s') = \begin{cases}
\alpha_{gin} & \text{going gin} \\
\alpha_{win} & \text{winning by knock} \\
-\alpha_{win} & \text{losing after knock} \\
-1.0 & \text{illegal move} \\
0 & \text{draw or ongoing}
\end{cases}
\]

We found that different models perform better with distinct reward scaling. Here's how the parameters vary between implementations:

\begin{table}[h]
\centering
\begin{tabular}{lccc}
\hline
Parameter & DQN/REINFORCE & MCTS \\
\hline
$\alpha_{gin}$ & 1.5 & 3.0 \\
$\alpha_{win}$ & 1.0 & 2.0 \\
$\alpha_{knock}$ & 0.5 & 1.0 \\
$\beta_{deadwood}$ & 0.01 & 0.03 \\
\hline
\end{tabular}
\end{table}

To encourage strategic play throughout the game, we incorporate four types of intermediate rewards:

\begin{enumerate}
\item \textbf{Deadwood Reduction:} When discarding, players receive a small reward proportional to the reduction in deadwood:
\[
R_{deadwood}(s,s') = \beta_{deadwood} \cdot \max(0, d(s) - d(s'))
\]

\item \textbf{Meld Formation:} Drawing from the discard pile to complete a meld earns a small bonus:
\[
R_{meld}(s,a,s') = 0.05 \cdot \mathbb{1}_{new\_meld}(s,a,s')
\]

\item \textbf{Knock Incentive:} A moderate reward encourages knocking when appropriate:
\[
R_{knock}(a) = \alpha_{knock} \cdot \mathbb{1}_{knock}(a)
\]

\item \textbf{Low Deadwood Bonus:} Winning with minimal deadwood earns extra points:
\[
R_{bonus}(s',a) = 0.05 \cdot (10 - d(s')) \cdot \mathbb{1}_{knock\_win}(s',a)
\]
\end{enumerate}

Notice how MCTS uses higher scaling factors compared to DQN and REINFORCE. This promotes more aggressive play, as MCTS can better evaluate the long-term consequences of bold moves through its tree search. The reward structure balances immediate tactical gains (reducing deadwood, forming melds) with strategic objectives (winning through gin or knock), creating agents that play both tactically and strategically sound Gin Rummy. 